# Пайплайн обработки PDF (учебник → задачи в БД)

Кратко: как PDF попадает в систему, как из него получаются задачи с номерами, страницами и ответами, и где может «съехать» ссылка на задачу.

---

## 0. Целевой пайплайн (как должно быть)

1. **OCR** выдаёт полный текстовый документ из PDF (постранично или целиком).
2. **Нормализация** — весь текст очищается от артефактов распознавания (латиница вместо кириллицы, переносы, нумерация, формулы и т.п.) → получаем **нормализованный текст**.
3. **Анализ нормализованного текста** — в нём выделяются: **теория параграфа** (определения, теоремы, доказательства), вопросы, задачи, решения, ответы.
4. **Распределение по БД** — выделенные блоки записываются в соответствующие таблицы: страницы (`pdf_pages`), задачи и решения (`problems`), **теория параграфа** (`section_theory`), ответы (через постобработку `link_answers`). Теория из `section_theory` подаётся в LLM для ответов на контрольные вопросы и обоснования решений.

**Реализовано в ingestion:** для каждой страницы OCR (EasyOCR/Tesseract) → нормализация текста → сегментация задач и **извлечение теории по параграфам (§)**. Результат пишется в БД (`pdf_pages.ocr_text`, `problems`, `section_theory`). **Целевая схема:** сырой OCR и нормализация — в **файлах** (.md по страницам/параграфам); в БД только проверенный итог. Подробно: `docs/OCR_FILES_AND_NORMALIZATION.md`, `docs/PIPELINE_FUTURE.md`. Ниже — детали и постобработка.

---

## 1. Появление книги и PDF в системе

| Шаг | Где | Что происходит |
|-----|-----|----------------|
| Классификация | `scripts/seed_books.py` или `apps/api/scripts/seed_books.py` | По имени файла и тексту первых страниц определяется **subject** (math, **geometry**, physics…), **grade**, **authors**. От этого зависят **title** и запись в `books`. |
| Создание книги | тот же seed | В БД создаётся запись в `books` (subject, grade, title и т.д.). |
| Источник PDF | seed или загрузка | В `pdf_sources` создаётся запись с `book_id`, `minio_key` (путь к файлу). |

**Важно:** Учебники геометрии должны идти как `subject=geometry` и title «Геометрия …». Если книга уже попала как «Математика», её можно поправить: `scripts/fix_geometry_books.py --book-id <id> --apply`.

---

## 2. Обработка PDF (ingestion) — страницы и задачи (текущее состояние)

Точка входа: **`apps/worker/ingestion.py`** → `process_pdf_source(pdf_source_id)`.

| Шаг | Код | Что происходит |
|-----|-----|----------------|
| Открытие PDF | PyMuPDF (`fitz`) | Чтение файла по `minio_key` / `local_pdf_path`. |
| **OCR** | **EasyOCR** (приоритет) или Tesseract (fallback) | Страница рендерится в PNG (150 DPI). Сначала EasyOCR (ru+en) для максимальной точности; при недоступности или ошибке — Tesseract. Пайплайн: OCR → нормализация → сегментация. |
| **Нормализация** | `clean_ocr_text(text)` (ocr_cleaner) | Текст страницы после OCR нормализуется от артефактов; результат пишется в `pdf_pages.ocr_text` и передаётся в сегментацию. |
| Сохранение страницы | БД | Для каждой страницы: строка в `pdf_pages` (page_num, **ocr_text — нормализованный**, ocr_confidence). |
| Сегментация задач | `segment_problems(text, page_num)` | По нормализованному тексту: паттерны (задача, упражнение, задание, вопрос, §, №, N. / N) и граница **«Решение.»** / **«Ответ.»** → `solution_text`. |
| Сохранение задач | БД | Для каждого блока: строка в `problems` (book_id, source_page_id, number, section, problem_text — условие, **solution_text** — блок после «Решение.» при наличии, page_ref, confidence). |
| **Теория параграфа** | `extract_and_save_section_theory()` | По всем страницам источника: разметка **§ N** и границы «Задачи»/«Упражнения»/«Вопросы к параграфу» → для каждого параграфа текст теории сохраняется в **`section_theory`** (book_id, section, theory_text, page_ref). Используется LLM для ответов на контрольные вопросы и обоснования решений. |

**От чего зависит корректность номера и страницы:**

- **Качество текста:** цифровой текст vs OCR. Плохой OCR → лишние/пропущенные границы задач, искажённые номера.
- **Правила сегментации** (`segment_problems`): если формат учебника не совпадает с паттернами (№, Упражнение, Задание, «N.»), границы задач определяются неверно → одна задача может разъехаться на несколько записей или несколько задач склеиться в одну.
- **Номер задачи** берётся из первого совпадения паттерна в блоке; при сбитых границах номер и `page_ref` относятся не к той задаче.

После ingestion у задач есть: `number`, `section` (часто ещё пустой), `problem_text`, `page_ref`. Ответов и решений пока нет.

---

## 3. Постобработка по книге (process_all)

Скрипт **`scripts/process_all.py --book-id <id>`** по очереди запускает шаги 1–4.

| Шаг | Скрипт | Что делает |
|-----|--------|------------|
| 1. Классификация | `classify_problems.py` | Тип задачи: question / exercise / unknown (по ключевым словам в тексте). |
| 2. Секции | `assign_sections.py` | По разметке в OCR страниц (§ N, «Параграф N») задачам проставляется `section` (параграф). От этого зависит привязка теории и ответов по параграфам. |
| 3. Ответы | `link_answers.py` | Ищет страницы с блоками «Ответы и указания» по тексту (`ответы` + `указан` + `задач`). В OCR этих страниц парсятся ответы по формату «§ N» + «номер задачи. ответ». Ответы записываются в `problems.answer_text` по (section, number). Если секция или номер задачи определились неверно на предыдущих шагах, ответ привяжется не к той задаче. |
| 4. Теория | `link_theory.py` | Из `pdf_pages.ocr_text` выделяются блоки теории по параграфам; позже используются для LLM-объяснений (раздел в worker). |

**Почему ссылка на задачу может быть некорректной:**

- Неверный **section** (assign_sections) → при link_answers ответ из другого параграфа может привязаться к задаче по номеру.
- Ошибки **OCR на страницах с ответами** → номера задач или форматы распознаны неверно, ответы попадают не на те номера.
- **Сегментация** на шаге ingestion отнесла кусок текста к неправильному номеру → в БД уже лежит «не та» задача с правильным page_ref, и ответ линкуется на неё.

---

## 4. Дополнительные скрипты (качество и структура)

| Скрипт | Назначение |
|--------|------------|
| `scripts/validate_ocr_quality.py --book-id N [--fix]` | Оценка качества OCR по задачам/страницам, опционально запись очищенного текста в `problem_text_clean`. |
| `scripts/parse_problem_parts.py --book-id N` | Разбиение задач с подпунктами (1) 2) 3)) на `problem_parts`, привязка ответов по частям. |
| `scripts/fix_geometry_books.py [--book-id N] --apply` | Исправление subject/title у книг по геометрии. |

Поиск по задачам (FTS) использует `COALESCE(problem_text_clean, problem_text)`; от качества OCR и сегментации напрямую зависит, какая задача и с каким `page_ref` окажется лучшим совпадением.

---

## 5. Цепочка «запрос → ответ → ссылка в дебаге»

1. Пользователь вводит запрос → worker вызывает **`search_problems(query)`** (FTS по тексту задач).
2. FTS возвращает задачи, упорядоченные по релевантности (ts_rank + бусты за наличие ответа и т.д.).
3. Берётся лучший результат (если score ≥ CONFIDENCE_THRESHOLD): его **book_title**, **number**, **page_ref**, **answer_text** и т.д. показываются в ответе и в дебаг-интерфейсе.
4. **Ссылка на место в учебнике** (книга, номер задачи, страница) всегда берётся из этой выбранной задачи. Она будет некорректной, если:
   - в БД по запросу лучше всего подошла **другая** задача (из-за FTS/OCR/сегментации), или
   - у правильной задачи неверно заполнены **number** / **section** / **page_ref** на этапах ingestion или process_all.

Итого: ссылку в дебаге нужно показывать (как сейчас); чтобы она была корректной, нужно улучшать ingestion (OCR, сегментацию), назначение секций и привязку ответов, а не скрывать ссылку.

---

## 6. Рекомендуемый порядок при разборе проблем

1. **Проверить книгу:** subject и title (геометрия vs математика) — при необходимости `fix_geometry_books.py`.
2. **Проверить OCR:** выборочно страницы и задачи через `validate_ocr_quality.py`, при необходимости `--fix` и перезапуск parse_problem_parts.
3. **Проверить сегментацию:** для проблемных страниц посмотреть в БД `problem_text`, `number`, `page_ref` — совпадают ли границы с реальными задачами в PDF.
4. **Проверить секции и ответы:** что `section` у задач совпадает с параграфами в учебнике; что страницы с ответами распознаются в link_answers и номера в тексте ответов совпадают с номерами задач.
5. При необходимости доработать паттерны в `segment_problems` (ingestion), в assign_sections и в link_answers под конкретный формат учебника.

---

## 7. Приведение к целевому пайплайну (что менять)

Чтобы пайплайн совпадал с целевым (OCR → нормализация → анализ → распределение):

| Что сделать | Где |
|-------------|-----|
| **Нормализация перед анализом** | В ingestion: после получения текста страницы (или полного документа) вызывать `clean_ocr_text()` (ocr_cleaner) и дальше работать с нормализованным текстом: писать его в `pdf_pages.ocr_text` (или в отдельное поле/файл) и передавать в сегментацию. |
| **Сегментация по нормализованному тексту** | В `segment_problems()` принимать уже нормализованный текст; добавить паттерны «Задача (N).», границу по «Решение.» и выделение блока решения в `solution_text`. |
| **Извлечение решений** | При сегментации или отдельным проходом: блок «Решение.» … до следующей задачи или конца страницы записывать в `problems.solution_text` у соответствующей задачи. |
| **Анализ теории / вопросов / ответов** | Скрипты assign_sections, link_answers, link_theory по возможности читать нормализованный текст (из `pdf_pages.ocr_text` после того, как он будет сохраняться нормализованным, или из `problem_text_clean` для задач). |
