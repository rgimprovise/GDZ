# Распределение по БД на основе решений LLM

Цель: **распределять данные из нормализованного .md в БД (задачи, теория параграфов) по решению LLM**, а не по скрипту с регулярками. Скрипт используется только для подготовки входов к LLM и разбора ответов, чтобы сэкономить токены и упростить задачу модели.

---

## 1. Что отправляем в LLM (запрос)

### 1.1. Зачем препроцессинг

- Не отправлять весь учебник одним куском — дорого и легко упереться в лимит контекста.
- Дать модели уже **разбитый на блоки** текст (страницы, параграфы, кандидаты в «задачу» / «теория»), чтобы она только **классифицировала и дооформляла**, а не искала границы с нуля.

### 1.2. Скрипт препроцессинга (экономия токенов)

Скрипт читает `data/ocr_normalized/{book_id}/{pdf_source_id}.md` и:

1. **Разбивает по страницам** — блоки `## Страница N` уже есть в файле.
2. **Внутри каждой страницы находит кандидаты на границы** (без решения «это задача» / «это теория»):
   - строки с `§ N`, «Параграф N» → граница параграфа;
   - строки «Задача (N)», «Упражнение N», «№ N», «N.» и т.п. → кандидат на начало задачи;
   - «Решение.» → граница условие/решение;
   - «Ответы», «Ответы и указания» → кандидат на блок ответов (можно отдельно или не слать в LLM).
3. **Формирует «кандидат-блоки»** — куски текста с метаданными:
   - `page_num`, `start_line`, `end_line`;
   - опционально: `hint` — «похоже на заголовок §», «похоже на задачу», «похоже на решение» (из правил/регулярок), чтобы LLM мог опереться на подсказку.

На выходе скрипта — список блоков, например:

```text
--- BLOCK 1 ---
page: 42
hint: section_header
§ 12. Сфера и шар. Касательная плоскость к сфере.

--- BLOCK 2 ---
page: 42
hint: theory
Плоскость, имеющая со сферой только одну общую точку, называется...

--- BLOCK 3 ---
page: 43
hint: problem_start
Задача (315). Докажите, что...

--- BLOCK 4 ---
page: 43
hint: solution
Решение. Пусть O — центр сферы...
```

Так мы **не просим LLM придумывать границы** — только подтвердить/исправить тип блока, выдать номер задачи, параграф и вынести условие/решение/ответ в нужные поля.

### 1.3. Формат запроса к API (промпт + структура)

- **Системный промпт**: роль (эксперт по разметке учебника), предмет (geometry/math/…), формат ответа (JSON или помеченные блоки), ограничения (номера задач — числа, § — без лишнего текста).
- **Пользовательский запрос**: либо батч таких блоков (например, 10–20 блоков с номерами страниц и подсказками), либо одна страница с уже нарезанными скриптом блоками. В обоих случаях явно указываем: «Для каждого блока верни: тип (theory | problem | solution | answer | other), section (например §12), number (если задача), problem_text, solution_text, answer_text (если есть), остальное в other или пропусти».

Пример тела запроса (упрощённо):

```text
Предмет: geometry. Ниже блоки текста из учебника после OCR. Для каждого блока определи тип и поля.

--- BLOCK 1 ---
page: 42
§ 12. Сфера и шар...

--- BLOCK 2 ---
page: 42
Плоскость, имеющая со сферой только одну общую точку...

--- BLOCK 3 ---
page: 43
Задача (315). Докажите, что...
```

Токены экономим за счёт того, что:
- в контекст попадают только нужные страницы/блоки (батчами);
- границы уже предложены скриптом (hint), LLM в основном классифицирует и нормализует поля.

### 1.4. Режим по параграфам и отсутствие § (OCR)

Реализовано два режима вызова LLM:

1. **По параграфам** (предпочтительно): текст разбивается по границам параграфов (`§ N`, `Параграф N`). В LLM отправляется **целиком один параграф** — модель разбивает его на смысловые блоки (теория, задачи, решение, ответы) и возвращает JSON с массивом блоков. Так модель получает полный контекст параграфа и меньше путает теорию с задачами.
2. **По блокам** (fallback): если параграфов не найдено или один параграф слишком длинный (>35k символов), используется препроцессинг по мелким блокам (как в 1.2) с подсказками hint и контекстом соседей.

**Отсутствие знака § из-за ошибки OCR**: если в тексте нет ни одного вхождения `§ N` или `Параграф N`, скрипт использует запасной вариант разбиения — по нумерованным заголовкам после пустой строки (строка вида `1. Заголовок параграфа`). Номер из такого заголовка подставляется в `section` (например `§1`). В промпте для параграфа явно указано: «Если в тексте нет знака параграфа (§) из-за ошибки OCR — используй для section номер из запроса».

---

## 2. Что ожидаем от LLM (ответ) и как пишем в БД

### 2.1. Структурированный ответ

Предпочтительно **JSON** (проще парсить и валидировать), например:

```json
{
  "blocks": [
    {
      "block_id": 1,
      "type": "section_theory",
      "section": "§12",
      "theory_text": "§ 12. Сфера и шар. Касательная плоскость к сфере.\n\nПлоскость, имеющая со сферой только одну общую точку..."
    },
    {
      "block_id": 2,
      "type": "theory",
      "section": "§12",
      "theory_text": "Плоскость, имеющая со сферой только одну общую точку..."
    },
    {
      "block_id": 3,
      "type": "problem",
      "section": "§12",
      "number": "315",
      "problem_text": "Докажите, что...",
      "solution_text": "Пусть O — центр сферы...",
      "answer_text": null
    }
  ]
}
```

Альтернатива — разметка в тексте (например, теги `[THEORY §12] ... [/THEORY]`, `[PROBLEM 315] ... [/PROBLEM]`), но JSON проще для скрипта и для слияния блоков теории по одному §.

### 2.2. Обработка ответа скриптом (запись в БД)

- **section_theory**: по полю `type` в (`section_theory`, `theory`) собираем все блоки с одним `section`; склеиваем `theory_text` в один текст; запись в `section_theory`: `book_id`, `section`, `theory_text`, `page_ref` (из номера страницы блока).
- **problems**: по `type === "problem"` создаём записи в `problems`: `book_id`, `source_page_id` (страница из блока), `number`, `section`, `problem_text`, `solution_text`, `answer_text` (если есть), `page_ref`.
- Блоки `solution` или `answer` без отдельного `problem` можно привязывать к последней задаче на странице (эвристика) или явно просить LLM всегда отдавать задачу с полями `problem_text`, `solution_text`, `answer_text`.

То есть **скрипт не принимает решений «что задачей, что теорией»** — он только:
- готовит батчи блоков для LLM;
- парсит ответ;
- маппит результат в существующие таблицы (section_theory, problems, при необходимости pdf_pages).

---

## 3. Пайплайн по шагам

| Шаг | Кто | Действие |
|-----|-----|----------|
| 1 | Скрипт | Читает нормализованный .md, режет на блоки по страницам и по границам (§, Задача, Решение., и т.д.), ставит hint. |
| 2 | Скрипт | Собирает батчи блоков (например, по 15–20 блоков или по 3–5 страницам), формирует промпт. |
| 3 | LLM API | Получает промпт, возвращает JSON с типами и полями для каждого блока. |
| 4 | Скрипт | Парсит JSON, объединяет теорию по §, пишет в section_theory; по задачам пишет в problems; при необходимости обновляет pdf_pages.ocr_text (или оставляет как есть). |

Чекпоинты и повтор при сбое можно делать по батчам (как для LLM-нормализации): сохранять прогресс по «обработанным страницам/батчам», при падении — продолжать с места остановки.

---

## 4. Итог

- **Запрос к LLM**: структурированный текст блоков (страница + hint) + чёткий системный промпт с форматом ответа (JSON).
- **Ответ**: JSON с типами блоков и полями (theory_text, problem_text, solution_text, answer_text, section, number).
- **Распределение по БД**: делается **только по решению LLM** (типы и поля из ответа); скрипт только подготавливает вход, батчует вызовы и пишет результат в БД.
- **Скрипт для экономии токенов**: препроцессинг (разрез по страницам и очевидным границам, подсказки hint) так и остаётся в коде; логика «это задача / это теория / номер / параграф» переносится в LLM.

Если нужно, следующий шаг — набросок конкретных промптов (системный + пользовательский) и схема JSON под текущие поля в `section_theory` и `problems`.
