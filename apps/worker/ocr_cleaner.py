"""
OCR Text Cleaner / Post-processor

–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Ç–∏–ø–∏—á–Ω—ã–µ –æ—à–∏–±–∫–∏ OCR –¥–ª—è —Ä—É—Å—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤:
- –õ–∞—Ç–∏–Ω–∏—Ü–∞ –≤–º–µ—Å—Ç–æ –∫–∏—Ä–∏–ª–ª–∏—Ü—ã (me ‚Üí —à–µ, ux ‚Üí –∏—Ö)
- –ù–µ–≤–µ—Ä–Ω—ã–µ —Ü–∏—Ñ—Ä—ã –≤ –Ω—É–º–µ—Ä–∞—Ü–∏–∏
- –ê—Ä—Ç–µ—Ñ–∞–∫—Ç—ã —Ñ–æ—Ä–º—É–ª –∏ —Å–∏–º–≤–æ–ª–æ–≤
- –ü–µ—Ä–µ–Ω–æ—Å—ã —Å–ª–æ–≤

–ê–≤—Ç–æ—Ä: TutorBot Team
"""

import re
from typing import Dict, List, Tuple


# ===========================================
# 1. –õ–∞—Ç–∏–Ω–∏—Ü–∞ ‚Üí –ö–∏—Ä–∏–ª–ª–∏—Ü–∞
# ===========================================

# –ü–æ—Ö–æ–∂–∏–µ —Å–∏–º–≤–æ–ª—ã: –ª–∞—Ç–∏–Ω—Å–∫–∞—è ‚Üí –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∞—è
LATIN_TO_CYRILLIC = {
    'a': '–∞', 'A': '–ê',
    'e': '–µ', 'E': '–ï',
    'o': '–æ', 'O': '–û',
    'p': '—Ä', 'P': '–†',
    'c': '—Å', 'C': '–°',
    'x': '—Ö', 'X': '–•',
    'y': '—É', 'Y': '–£',
    'H': '–ù',
    'K': '–ö', 'k': '–∫',
    'M': '–ú',
    'T': '–¢',
    'B': '–í',
    'm': '—Ç',  # —á–∞—Å—Ç–æ –ø—É—Ç–∞–µ—Ç—Å—è –≤ —Å–ª–æ–≤–∞—Ö
}

# –ß–∞—Å—Ç—ã–µ OCR-–æ—à–∏–±–∫–∏: –ª–∞—Ç–∏–Ω—Å–∫–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ ‚Üí —Ä—É—Å—Å–∫–∏–µ —Å–ª–æ–≤–∞
LATIN_SEQUENCES = {
    # –û–∫–æ–Ω—á–∞–Ω–∏—è –∏ —á–∞—Å—Ç–∏ —Å–ª–æ–≤
    'me': '—à–µ',      # –±–æ–ª—å—à–µ ‚Üí –±–æ–ª—å-me
    'ux': '–∏—Ö',      # –∏—Ö ‚Üí ux
    'OHH': '–æ–Ω–∏',    # –æ–Ω–∏ ‚Üí OHH
    'OHU': '–æ–Ω–∏',
    'pa3a': '—Ä–∞–∑–∞',  # —Ä–∞–∑–∞ ‚Üí pa3a
    'pasa': '—Ä–∞–∑–∞',  # —Ä–∞–∑–∞ ‚Üí pasa
    'pa3': '—Ä–∞–∑',
    'caMbIX': '—Å–∞–º—ã—Ö',
    'yroJI': '—É–≥–æ–ª',
    'yrJIa': '—É–≥–ª–∞',
    'yroJIa': '—É–≥–ª–∞',
    'yrJIoB': '—É–≥–ª–æ–≤',
    'CMeXHbIe': '—Å–º–µ–∂–Ω—ã–µ',
    'CMeXHbIX': '—Å–º–µ–∂–Ω—ã—Ö',
    'cMeXHbIe': '—Å–º–µ–∂–Ω—ã–µ',
    'paBHo': '—Ä–∞–≤–Ω–æ',
    'paBHa': '—Ä–∞–≤–Ω–∞',
    'paBHbI': '—Ä–∞–≤–Ω—ã',
    'MeHbme': '–º–µ–Ω—å—à–µ',
    'MeHee': '–º–µ–Ω–µ–µ',
    '6oJIbme': '–±–æ–ª—å—à–µ',
    '6oJIee': '–±–æ–ª–µ–µ',
    'HafiTH': '–Ω–∞–π—Ç–∏',
    'HafiAHTe': '–Ω–∞–π–¥–∏—Ç–µ',
    'HaiTH': '–Ω–∞–π—Ç–∏',
    '3HaK': '–∑–Ω–∞–∫',
    'qepTa': '—á–µ—Ä—Ç–∞',
    'npHMofi': '–ø—Ä—è–º–æ–π',
    'OCTpbIfi': '–æ—Å—Ç—Ä—ã–π',
    'TynOfi': '—Ç—É–ø–æ–π',
    '3aAaqH': '–∑–∞–¥–∞—á–∏',
    '3aAaqa': '–∑–∞–¥–∞—á–∞',
    'OTBeT': '–æ—Ç–≤–µ—Ç',
    'OTBeTbI': '–æ—Ç–≤–µ—Ç—ã',
    'pemeHHe': '—Ä–µ—à–µ–Ω–∏–µ',
    'ynpaxHeHHe': '—É–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ',
    'ynp': '—É–ø—Ä',
    'AoKa3aTb': '–¥–æ–∫–∞–∑–∞—Ç—å',
    'TeopeMa': '—Ç–µ–æ—Ä–µ–º–∞',
    'onpeAeJIeHHe': '–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ',
    'cBofiCTBo': '—Å–≤–æ–π—Å—Ç–≤–æ',
    'CJIeACTBHe': '—Å–ª–µ–¥—Å—Ç–≤–∏–µ',
    'aKCHoMa': '–∞–∫—Å–∏–æ–º–∞',
    'naparpaa)': '–ø–∞—Ä–∞–≥—Ä–∞—Ñ',
    'naparpap': '–ø–∞—Ä–∞–≥—Ä–∞—Ñ',
    'rJIaBa': '–≥–ª–∞–≤–∞',
}

# –ß–∞—Å—Ç—ã–µ –æ–¥–∏–Ω–æ—á–Ω—ã–µ –∑–∞–º–µ–Ω—ã –≤–Ω—É—Ç—Ä–∏ —Å–ª–æ–≤
INLINE_FIXES = [
    (r'6o([–ª–õ])', r'–±–æ\1'),           # 6–æ–ª—å—à–µ ‚Üí –±–æ–ª—å—à–µ
    (r'([–∞-—è–ê-–Ø])6([–∞-—è–ê-–Ø])', r'\1–±\2'),  # 6 –≤–Ω—É—Ç—Ä–∏ —Å–ª–æ–≤–∞ ‚Üí –±
    (r'([–∞-—è–ê-–Ø])3([–∞-—è–ê-–Ø])', r'\1–∑\2'),  # 3 –≤–Ω—É—Ç—Ä–∏ —Å–ª–æ–≤–∞ ‚Üí –∑  
    (r'([–∞-—è–ê-–Ø])0([–∞-—è–ê-–Ø])', r'\1–æ\2'),  # 0 –≤–Ω—É—Ç—Ä–∏ —Å–ª–æ–≤–∞ ‚Üí –æ
    (r'([–∞-—è–ê-–Ø])1([–∞-—è–ê-–Ø])', r'\1—ñ\2'),  # 1 –≤–Ω—É—Ç—Ä–∏ —Å–ª–æ–≤–∞ ‚Üí i (—Ä–µ–¥–∫–æ)
]


def fix_latin_to_cyrillic(text: str) -> str:
    """Replace Latin characters that look like Cyrillic in Russian context."""
    
    # 1. –°–Ω–∞—á–∞–ª–∞ —Ñ–∏–∫—Å–∏–º –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    for lat, cyr in LATIN_SEQUENCES.items():
        text = text.replace(lat, cyr)
    
    # 2. –ó–∞—Ç–µ–º —Å–º–µ—à–∞–Ω–Ω—ã–µ —Å–ª–æ–≤–∞ (–ª–∞—Ç–∏–Ω—Å–∫–∏–µ –±—É–∫–≤—ã –≤–Ω—É—Ç—Ä–∏ –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∏—Ö —Å–ª–æ–≤)
    def fix_mixed_word(match):
        word = match.group(0)
        # –ï—Å–ª–∏ —Å–ª–æ–≤–æ —Å–æ–¥–µ—Ä–∂–∏—Ç –∏ –∫–∏—Ä–∏–ª–ª–∏—Ü—É –∏ –ª–∞—Ç–∏–Ω–∏—Ü—É - –∫–æ–Ω–≤–µ—Ä—Ç–∏–º –ª–∞—Ç–∏–Ω–∏—Ü—É
        has_cyrillic = any('\u0400' <= c <= '\u04FF' for c in word)
        has_latin = any('a' <= c.lower() <= 'z' for c in word)
        
        if has_cyrillic and has_latin:
            result = []
            for c in word:
                if c in LATIN_TO_CYRILLIC:
                    result.append(LATIN_TO_CYRILLIC[c])
                else:
                    result.append(c)
            return ''.join(result)
        return word
    
    # –ò—â–µ–º "—Å–ª–æ–≤–∞" - –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –±—É–∫–≤
    text = re.sub(r'[a-zA-Z–∞-—è–ê-–Ø—ë–Å]+', fix_mixed_word, text)
    
    # 3. Inline fixes (—Ü–∏—Ñ—Ä—ã –≤–Ω—É—Ç—Ä–∏ —Å–ª–æ–≤)
    for pattern, replacement in INLINE_FIXES:
        text = re.sub(pattern, replacement, text)
    
    return text


# ===========================================
# 2. –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–µ—Ä–µ–Ω–æ—Å–æ–≤
# ===========================================

def fix_hyphenation(text: str) -> str:
    """Fix word hyphenation from line breaks."""
    # "–±–æ–ª—å-\n—à–µ" ‚Üí "–±–æ–ª—å—à–µ"
    text = re.sub(r'(\w+)-\s*\n\s*(\w+)', r'\1\2', text)
    # "–±–æ–ª—å- —à–µ" ‚Üí "–±–æ–ª—å—à–µ"  
    text = re.sub(r'(\w+)-\s+(\w+)', r'\1\2', text)
    return text


# ===========================================
# 3. –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω—É–º–µ—Ä–∞—Ü–∏–∏
# ===========================================

def fix_numbering_in_context(text: str) -> str:
    """
    Fix numbering errors based on context.
    E.g., "1) ... 2) ... 8) ..." ‚Üí "1) ... 2) ... 3) ..."
    """
    # –ù–∞–π—Ç–∏ –≤—Å–µ –Ω—É–º–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–∞ "N)" –≥–¥–µ N - —Ü–∏—Ñ—Ä–∞
    pattern = r'\b(\d)\)'
    
    matches = list(re.finditer(pattern, text))
    
    if len(matches) < 2:
        return text
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å
    result = text
    offset = 0
    expected_num = None
    
    for i, match in enumerate(matches):
        current_num = int(match.group(1))
        
        if expected_num is None:
            expected_num = current_num + 1
            continue
        
        # –ï—Å–ª–∏ –Ω–æ–º–µ—Ä –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –æ–∂–∏–¥–∞–µ–º—ã–º
        if current_num != expected_num and expected_num <= 9:
            # –°–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –æ—à–∏–±–∫–∞ OCR
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ä–∞–∑–Ω–∏—Ü–∞ –±–æ–ª—å—à–∞—è (8 –≤–º–µ—Å—Ç–æ 3, –Ω–µ 4 –≤–º–µ—Å—Ç–æ 3)
            if abs(current_num - expected_num) > 1:
                start = match.start() + offset
                end = match.end() + offset
                result = result[:start] + str(expected_num) + ')' + result[end:]
                offset += len(str(expected_num)) - len(match.group(0)) + 1
        
        expected_num = current_num + 1 if current_num == expected_num else expected_num + 1
    
    return result


# ===========================================
# 4. –§–æ—Ä–º—É–ª—ã –∏ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã
# ===========================================

MATH_FIXES = {
    # –ì—Ä–∞–¥—É—Å—ã
    '–≥—Ä–∞–¥—É—Å–æ–≤': '¬∞',
    '–≥—Ä–∞–¥—É—Å–∞': '¬∞',
    '–≥—Ä–∞–¥—É—Å ': '¬∞ ',
    '¬∞ ¬∞': '¬∞',
    
    # –°—Ç–µ–ø–µ–Ω–∏
    'm2': 'm¬≤', 
    '–º2': '–º¬≤',
    'cm2': '—Å–º¬≤',
    '—Å–º2': '—Å–º¬≤',
    'm3': 'm¬≥',
    '–º3': '–º¬≥',
    'cm3': '—Å–º¬≥',
    '—Å–º3': '—Å–º¬≥',
    
    # –î—Ä–æ–±–∏
    '1/2': '¬Ω',
    '1/3': '‚Öì',
    '1/4': '¬º',
    '3/4': '¬æ',
    
    # –ó–Ω–∞–∫–∏
    '<=': '‚â§',
    '>=': '‚â•',
    '!=': '‚â†',
    '+-': '¬±',
    '~=': '‚âà',
    
    # –£–≥–ª—ã
    '<ABC': '‚à†ABC',
    '<–ê–í–°': '‚à†–ê–í–°',
    '/_': '‚à†',
    
    # –î—Ä—É–≥–æ–µ
    '||': '‚à•',  # –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ—Å—Ç—å
    '_|_': '‚ä•',  # –ø–µ—Ä–ø–µ–Ω–¥–∏–∫—É–ª—è—Ä–Ω–æ—Å—Ç—å
}


def fix_math_symbols(text: str) -> str:
    """Fix common math symbol OCR errors."""
    for wrong, right in MATH_FIXES.items():
        text = text.replace(wrong, right)
    
    # –ò—Å–ø—Ä–∞–≤–∏—Ç—å "m?" –≥–¥–µ ? - –∞—Ä—Ç–µ—Ñ–∞–∫—Ç –æ—Ç ¬≥
    text = re.sub(r'm\?', 'm¬≥', text)
    text = re.sub(r'–º\?', '–º¬≥', text)
    
    # –ò—Å–ø—Ä–∞–≤–∏—Ç—å "@" ‚Üí "Q" –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ (–ó–ê@)
    text = re.sub(r'([–ê-–Ø])@', r'\1Q', text)
    
    return text


# ===========================================
# 5. –ö–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
# ===========================================

# –°–ª–æ–≤–∞—Ä—å —á–∞—Å—Ç—ã—Ö —Å–ª–æ–≤ –≤ —É—á–µ–±–Ω–∏–∫–∞—Ö (–¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏)
COMMON_MATH_WORDS = {
    # –ì–µ–æ–º–µ—Ç—Ä–∏—è
    '—É–≥–æ–ª', '—É–≥–ª—ã', '—É–≥–ª–∞', '—É–≥–ª–æ–≤', '—É–≥–ª–µ', '—É–≥–ª–æ–º',
    '—Å–º–µ–∂–Ω—ã–µ', '—Å–º–µ–∂–Ω—ã—Ö', '—Å–º–µ–∂–Ω—ã–π', '—Å–º–µ–∂–Ω–æ–≥–æ',
    '–≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–µ', '–≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–π', '–≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã—Ö',
    '–ø—Ä—è–º–æ–π', '–ø—Ä—è–º–∞—è', '–ø—Ä—è–º—É—é', '–ø—Ä—è–º—ã–µ', '–ø—Ä—è–º—ã—Ö',
    '–æ—Å—Ç—Ä—ã–π', '–æ—Å—Ç—Ä—ã–µ', '–æ—Å—Ç—Ä–æ–≥–æ', '–æ—Å—Ç—Ä—ã—Ö',
    '—Ç—É–ø–æ–π', '—Ç—É–ø—ã–µ', '—Ç—É–ø–æ–≥–æ', '—Ç—É–ø—ã—Ö',
    '—Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–π', '—Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–µ',
    '—Ç—Ä–µ—É–≥–æ–ª—å–Ω–∏–∫', '—Ç—Ä–µ—É–≥–æ–ª—å–Ω–∏–∫–∞', '—Ç—Ä–µ—É–≥–æ–ª—å–Ω–∏–∫–∏', '—Ç—Ä–µ—É–≥–æ–ª—å–Ω–∏–∫–æ–≤',
    '–∫–≤–∞–¥—Ä–∞—Ç', '–∫–≤–∞–¥—Ä–∞—Ç–∞', '–∫–≤–∞–¥—Ä–∞—Ç—ã',
    '–ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫', '–ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∞',
    '–æ–∫—Ä—É–∂–Ω–æ—Å—Ç—å', '–æ–∫—Ä—É–∂–Ω–æ—Å—Ç–∏',
    '—Ä–∞–¥–∏—É—Å', '—Ä–∞–¥–∏—É—Å–∞', '—Ä–∞–¥–∏—É—Å–æ–º',
    '–¥–∏–∞–º–µ—Ç—Ä', '–¥–∏–∞–º–µ—Ç—Ä–∞',
    '–ø–µ—Ä–∏–º–µ—Ç—Ä', '–ø–µ—Ä–∏–º–µ—Ç—Ä–∞',
    '–ø–ª–æ—â–∞–¥—å', '–ø–ª–æ—â–∞–¥–∏',
    '—Å—Ç–æ—Ä–æ–Ω–∞', '—Å—Ç–æ—Ä–æ–Ω—ã', '—Å—Ç–æ—Ä–æ–Ω', '—Å—Ç–æ—Ä–æ–Ω–æ–π',
    '–≤–µ—Ä—à–∏–Ω–∞', '–≤–µ—Ä—à–∏–Ω—ã', '–≤–µ—Ä—à–∏–Ω',
    '–æ—Å–Ω–æ–≤–∞–Ω–∏–µ', '–æ—Å–Ω–æ–≤–∞–Ω–∏—è',
    '–≤—ã—Å–æ—Ç–∞', '–≤—ã—Å–æ—Ç—ã', '–≤—ã—Å–æ—Ç',
    '–º–µ–¥–∏–∞–Ω–∞', '–º–µ–¥–∏–∞–Ω—ã',
    '–±–∏—Å—Å–µ–∫—Ç—Ä–∏—Å–∞', '–±–∏—Å—Å–µ–∫—Ç—Ä–∏—Å—ã',
    '–ø–µ—Ä–ø–µ–Ω–¥–∏–∫—É–ª—è—Ä', '–ø–µ—Ä–ø–µ–Ω–¥–∏–∫—É–ª—è—Ä–Ω—ã', '–ø–µ—Ä–ø–µ–Ω–¥–∏–∫—É–ª—è—Ä–Ω–æ',
    '–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã', '–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ', '–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ',
    '—Ç–æ—á–∫–∞', '—Ç–æ—á–∫–∏', '—Ç–æ—á–µ–∫', '—Ç–æ—á–∫—É',
    '–æ—Ç—Ä–µ–∑–æ–∫', '–æ—Ç—Ä–µ–∑–∫–∞', '–æ—Ç—Ä–µ–∑–∫–∏', '–æ—Ç—Ä–µ–∑–∫–æ–≤',
    '–ª—É—á', '–ª—É—á–∞', '–ª—É—á–∏', '–ª—É—á–µ–π',
    '–ø–ª–æ—Å–∫–æ—Å—Ç—å', '–ø–ª–æ—Å–∫–æ—Å—Ç–∏',
    
    # –ê–ª–≥–µ–±—Ä–∞
    '—É—Ä–∞–≤–Ω–µ–Ω–∏–µ', '—É—Ä–∞–≤–Ω–µ–Ω–∏—è', '—É—Ä–∞–≤–Ω–µ–Ω–∏–π',
    '–Ω–µ—Ä–∞–≤–µ–Ω—Å—Ç–≤–æ', '–Ω–µ—Ä–∞–≤–µ–Ω—Å—Ç–≤–∞',
    '–≤—ã—Ä–∞–∂–µ–Ω–∏–µ', '–≤—ã—Ä–∞–∂–µ–Ω–∏—è',
    '—Ñ–æ—Ä–º—É–ª–∞', '—Ñ–æ—Ä–º—É–ª—ã', '—Ñ–æ—Ä–º—É–ª',
    '–∫–æ—Ä–µ–Ω—å', '–∫–æ—Ä–Ω–∏', '–∫–æ—Ä–Ω–µ–π',
    '—Ä–µ—à–µ–Ω–∏–µ', '—Ä–µ—à–µ–Ω–∏—è', '—Ä–µ—à–µ–Ω–∏–π',
    '–æ—Ç–≤–µ—Ç', '–æ—Ç–≤–µ—Ç—ã', '–æ—Ç–≤–µ—Ç–æ–≤',
    '–∑–Ω–∞—á–µ–Ω–∏–µ', '–∑–Ω–∞—á–µ–Ω–∏—è', '–∑–Ω–∞—á–µ–Ω–∏–π',
    '–ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è', '–ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ', '–ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π',
    '–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç', '–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã',
    '–º–Ω–æ–∂–∏—Ç–µ–ª—å', '–º–Ω–æ–∂–∏—Ç–µ–ª–∏',
    '–¥–µ–ª–∏—Ç–µ–ª—å', '–¥–µ–ª–∏—Ç–µ–ª–∏',
    '–¥–µ–ª–∏–º–æ–µ', '–¥–µ–ª–∏–º–æ–≥–æ',
    '—á–∞—Å—Ç–Ω–æ–µ', '—á–∞—Å—Ç–Ω–æ–≥–æ',
    '–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ', '–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è',
    '—Å—É–º–º–∞', '—Å—É–º–º—ã', '—Å—É–º–º',
    '—Ä–∞–∑–Ω–æ—Å—Ç—å', '—Ä–∞–∑–Ω–æ—Å—Ç–∏',
    '–¥—Ä–æ–±—å', '–¥—Ä–æ–±–∏', '–¥—Ä–æ–±–µ–π',
    '—á–∏—Å–ª–∏—Ç–µ–ª—å', '—á–∏—Å–ª–∏—Ç–µ–ª—è',
    '–∑–Ω–∞–º–µ–Ω–∞—Ç–µ–ª—å', '–∑–Ω–∞–º–µ–Ω–∞—Ç–µ–ª—è',
    '—Å—Ç–µ–ø–µ–Ω—å', '—Å—Ç–µ–ø–µ–Ω–∏', '—Å—Ç–µ–ø–µ–Ω–µ–π',
    '–ø–æ–∫–∞–∑–∞—Ç–µ–ª—å', '–ø–æ–∫–∞–∑–∞—Ç–µ–ª—è',
    '—Ñ—É–Ω–∫—Ü–∏—è', '—Ñ—É–Ω–∫—Ü–∏–∏', '—Ñ—É–Ω–∫—Ü–∏–π',
    '–≥—Ä–∞—Ñ–∏–∫', '–≥—Ä–∞—Ñ–∏–∫–∞', '–≥—Ä–∞—Ñ–∏–∫–∏',
    
    # –û–±—â–∏–µ
    '–Ω–∞–π–¥–∏—Ç–µ', '–Ω–∞–π—Ç–∏', '–Ω–∞–π–¥–µ–Ω',
    '–≤—ã—á–∏—Å–ª–∏—Ç–µ', '–≤—ã—á–∏—Å–ª–∏—Ç—å',
    '–¥–æ–∫–∞–∂–∏—Ç–µ', '–¥–æ–∫–∞–∑–∞—Ç—å', '–¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–æ',
    '–æ–ø—Ä–µ–¥–µ–ª–∏—Ç–µ', '–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å',
    '–ø–æ—Å—Ç—Ä–æ–π—Ç–µ', '–ø–æ—Å—Ç—Ä–æ–∏—Ç—å', '–ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ',
    '—Ä–µ—à–∏—Ç–µ', '—Ä–µ—à–∏—Ç—å',
    '—É–ø—Ä–æ—Å—Ç–∏—Ç–µ', '—É–ø—Ä–æ—Å—Ç–∏—Ç—å',
    '—Å—Ä–∞–≤–Ω–∏—Ç–µ', '—Å—Ä–∞–≤–Ω–∏—Ç—å',
    '—Ä–∞–≤–Ω–æ', '—Ä–∞–≤–Ω—ã', '—Ä–∞–≤–Ω–∞', '—Ä–∞–≤–µ–Ω',
    '–±–æ–ª—å—à–µ', '–º–µ–Ω—å—à–µ',
    '–µ—Å–ª–∏', '–∫–æ–≥–¥–∞', '—Ç–æ–≥–¥–∞',
    '–¥–∞–Ω–æ', '–¥–∞–Ω–Ω—ã–π', '–¥–∞–Ω–Ω—ã–µ',
    '–∏–∑–≤–µ—Å—Ç–Ω–æ', '–∏–∑–≤–µ—Å—Ç–Ω—ã–π',
    '—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ', '–∑–Ω–∞—á–∏—Ç', '–ø–æ—ç—Ç–æ–º—É',
    '—Ç–µ–æ—Ä–µ–º–∞', '—Ç–µ–æ—Ä–µ–º—ã', '—Ç–µ–æ—Ä–µ–º',
    '–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ', '–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è',
    '—Å–≤–æ–π—Å—Ç–≤–æ', '—Å–≤–æ–π—Å—Ç–≤–∞', '—Å–≤–æ–π—Å—Ç–≤',
    '–ø—Ä–∏–∑–Ω–∞–∫', '–ø—Ä–∏–∑–Ω–∞–∫–∏', '–ø—Ä–∏–∑–Ω–∞–∫–æ–≤',
    '–∞–∫—Å–∏–æ–º–∞', '–∞–∫—Å–∏–æ–º—ã',
    '—Å–ª–µ–¥—Å—Ç–≤–∏–µ', '—Å–ª–µ–¥—Å—Ç–≤–∏—è',
}

# –û–±—â–∏–µ OCR-–æ—à–∏–±–∫–∏ –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É (–ø–∞—Ç—Ç–µ—Ä–Ω ‚Üí –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ)
CONTEXTUAL_FIXES = [
    # "—Å–º–µ.–Ω—ã–µ —É–≥–ª—ã" ‚Üí "—Å–º–µ–∂–Ω—ã–µ —É–≥–ª—ã" (—Ç–æ—á–∫–∞ –≤–º–µ—Å—Ç–æ –∂)
    (r'—Å–º–µ[.]–Ω—ã–µ', '—Å–º–µ–∂–Ω—ã–µ'),
    (r'CME[.]HbIe', '—Å–º–µ–∂–Ω—ã–µ'),
    
    # –ß–∏—Å–ª–∞ + –≥—Ä–∞–¥—É—Å—ã
    (r'(\d+)\s*rpanyco–≤', r'\1 –≥—Ä–∞–¥—É—Å–æ–≤'),
    (r'(\d+)\s*rpa–¥yco–≤', r'\1 –≥—Ä–∞–¥—É—Å–æ–≤'),
    (r'(\d+)\s*rpa–¥yc', r'\1 –≥—Ä–∞–¥—É—Å'),
    
    # "–æ–¥–∏–Ω –∏–∑ –Ω–∏—Ö" –ø–∞—Ç—Ç–µ—Ä–Ω—ã
    (r'o–¥u–Ω\s+u–∑\s+–Ωux', '–æ–¥–∏–Ω –∏–∑ –Ω–∏—Ö'),
    (r'o–¥–∏–Ω\s+–∏–∑\s+–Ω–∏x', '–æ–¥–∏–Ω –∏–∑ –Ω–∏—Ö'),
    (r'o–¥–∏–Ω\s+–∏–∑\s+–Ωux', '–æ–¥–∏–Ω –∏–∑ –Ω–∏—Ö'),
    
    # "–≤ N —Ä–∞–∑(–∞)" –ø–∞—Ç—Ç–µ—Ä–Ω—ã  
    (r'–≤\s+(\d+)\s*pa[3–∑]a?', r'–≤ \1 —Ä–∞–∑–∞'),
    (r'–≤\s+(\d+)\s*pa[3–∑]', r'–≤ \1 —Ä–∞–∑'),
    
    # –¢–µ–æ—Ä–µ–º—ã –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
    (r'[t—Ç]–µ–æ—Ä–µ–º–∞', '—Ç–µ–æ—Ä–µ–º–∞'),
    (r'o–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ', '–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ'),
    (r'c–≤–æ–π—Å—Ç–≤–æ', '—Å–≤–æ–π—Å—Ç–≤–æ'),
    (r'–¥o–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–æ', '–¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–æ'),
    (r'–¥–æ–∫–∞[3–∑]–∞—Ç–µ–ª—å—Å—Ç–≤–æ', '–¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–æ'),
    
    # –†–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—ë–Ω–Ω—ã–µ –æ–∫–æ–Ω—á–∞–Ω–∏—è
    (r'(\w+)ckuu\b', r'\1—Å–∫–∏–π'),
    (r'(\w+)cku–π\b', r'\1—Å–∫–∏–π'),
    (r'(\w+)–µ—Ü–∫–∏–π\b', r'\1–µ—Ü–∫–∏–π'),
]


def apply_contextual_fixes(text: str) -> str:
    """
    Apply context-aware fixes based on common patterns in textbooks.
    """
    for pattern, replacement in CONTEXTUAL_FIXES:
        text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)
    
    return text


def fix_words_by_dictionary(text: str, max_words: int = 200) -> str:
    """
    Fix words that are close to known dictionary words.
    Uses simple edit distance for common words.
    
    Args:
        text: Input text
        max_words: Maximum number of words to process (for performance)
    """
    words = text.split()
    
    # Performance optimization: skip if too many words
    if len(words) > max_words:
        return text
    
    fixed_words = []
    
    # Pre-filter dictionary by length buckets for faster lookup
    dict_by_len = {}
    for w in COMMON_MATH_WORDS:
        wlen = len(w)
        if wlen not in dict_by_len:
            dict_by_len[wlen] = []
        dict_by_len[wlen].append(w)
    
    for word in words:
        # –£–±–∏—Ä–∞–µ–º –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        clean_word = re.sub(r'[^\w]', '', word.lower())
        
        if len(clean_word) < 4 or len(clean_word) > 15:
            fixed_words.append(word)
            continue
        
        # Quick check - if already in dictionary, skip
        if clean_word in COMMON_MATH_WORDS:
            fixed_words.append(word)
            continue
        
        # Only check words with similar length
        best_match = None
        best_distance = 3  # Only accept up to 2 errors
        
        for delta in [0, 1, -1, 2, -2]:
            target_len = len(clean_word) + delta
            if target_len not in dict_by_len:
                continue
            
            for known_word in dict_by_len[target_len]:
                # Quick filter: first char should match or differ by 1
                if clean_word[0] != known_word[0]:
                    continue
                
                distance = levenshtein_simple(clean_word, known_word)
                
                if distance < best_distance:
                    best_distance = distance
                    best_match = known_word
                    if distance == 1:  # Good enough
                        break
            
            if best_distance == 1:
                break
        
        if best_match and best_distance > 0 and best_distance < 3:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–≥–∏—Å—Ç—Ä –∏ –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é –æ—Ä–∏–≥–∏–Ω–∞–ª–∞
            fixed = preserve_case(word, best_match)
            fixed_words.append(fixed)
        else:
            fixed_words.append(word)
    
    return ' '.join(fixed_words)


def levenshtein_simple(s1: str, s2: str) -> int:
    """
    Simple Levenshtein distance calculation.
    For performance, only calculates for short strings.
    """
    if len(s1) > 15 or len(s2) > 15:
        return abs(len(s1) - len(s2))
    
    if len(s1) < len(s2):
        s1, s2 = s2, s1
    
    if len(s2) == 0:
        return len(s1)
    
    previous_row = range(len(s2) + 1)
    
    for i, c1 in enumerate(s1):
        current_row = [i + 1]
        for j, c2 in enumerate(s2):
            insertions = previous_row[j + 1] + 1
            deletions = current_row[j] + 1
            substitutions = previous_row[j] + (c1 != c2)
            current_row.append(min(insertions, deletions, substitutions))
        previous_row = current_row
    
    return previous_row[-1]


def preserve_case(original: str, replacement: str) -> str:
    """
    Apply the case pattern of original to replacement.
    """
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é
    prefix = ''
    suffix = ''
    
    while original and not original[0].isalpha():
        prefix += original[0]
        original = original[1:]
    
    while original and not original[-1].isalpha():
        suffix = original[-1] + suffix
        original = original[:-1]
    
    if not original:
        return prefix + replacement + suffix
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ä–µ–≥–∏—Å—Ç—Ä
    result = []
    for i, char in enumerate(replacement):
        if i < len(original):
            if original[i].isupper():
                result.append(char.upper())
            else:
                result.append(char.lower())
        else:
            result.append(char)
    
    return prefix + ''.join(result) + suffix


def fix_mathematical_context(text: str) -> str:
    """
    Fix OCR errors in mathematical expressions context.
    """
    # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –≤ —É—Ä–∞–≤–Ω–µ–Ω–∏—è—Ö: "2x" –Ω–æ –Ω–µ "2 –∏–∫—Å"
    # "2—Ö" (–∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∏–π —Ö) ‚Üí "2x" (–ª–∞—Ç–∏–Ω—Å–∫–∏–π x) –≤ –º–∞—Ç. –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
    text = re.sub(r'(\d)—Ö\b', r'\1x', text)  # 2—Ö ‚Üí 2x
    text = re.sub(r'\b—Ö(\d)', r'x\1', text)  # —Ö2 ‚Üí x2
    
    # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º y/—É –≤ –º–∞—Ç. –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
    text = re.sub(r'(\d)—É\b', r'\1y', text)  # 2—É ‚Üí 2y
    text = re.sub(r'\b—É\s*=', r'y =', text)  # —É = ‚Üí y =
    
    # –ó–Ω–∞–∫ —É–º–Ω–æ–∂–µ–Ω–∏—è
    text = re.sub(r'(\d)\s*[—Öx]\s*(\d)', r'\1 √ó \2', text)  # 2 x 3 ‚Üí 2 √ó 3
    
    # –°–∫–æ–±–∫–∏ –≤ —Ñ–æ—Ä–º—É–ª–∞—Ö
    text = re.sub(r'\(\s+', '(', text)
    text = re.sub(r'\s+\)', ')', text)
    
    # –ó–Ω–∞–∫ —Ä–∞–≤–µ–Ω—Å—Ç–≤–∞
    text = re.sub(r'\s+=\s+', ' = ', text)
    
    return text


def fix_sentence_boundaries(text: str) -> str:
    """
    Fix sentence boundary issues from OCR.
    """
    # –ü—Ä–æ–±–µ–ª –ø–æ—Å–ª–µ —Ç–æ—á–∫–∏ –ø–µ—Ä–µ–¥ –∑–∞–≥–ª–∞–≤–Ω–æ–π
    text = re.sub(r'\.([–ê-–ØA-Z])', r'. \1', text)
    
    # –ü—Ä–æ–±–µ–ª –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π
    text = re.sub(r',([–∞-—è–ê-–Øa-zA-Z])', r', \1', text)
    
    # –£–±—Ä–∞—Ç—å –ø—Ä–æ–±–µ–ª –ø–µ—Ä–µ–¥ —Ç–æ—á–∫–æ–π/–∑–∞–ø—è—Ç–æ–π
    text = re.sub(r'\s+([.,;:!?])', r'\1', text)
    
    return text


# ===========================================
# 6. –û–±—â–∞—è –æ—á–∏—Å—Ç–∫–∞
# ===========================================

def clean_whitespace(text: str) -> str:
    """Normalize whitespace."""
    # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã ‚Üí –æ–¥–∏–Ω
    text = re.sub(r'[ \t]+', ' ', text)
    # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã ‚Üí –¥–≤–∞
    text = re.sub(r'\n{3,}', '\n\n', text)
    # –ü—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ/–∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫
    text = '\n'.join(line.strip() for line in text.split('\n'))
    return text.strip()


def remove_page_artifacts(text: str) -> str:
    """Remove page numbers and headers/footers."""
    # –ù–æ–º–µ—Ä–∞ —Å—Ç—Ä–∞–Ω–∏—Ü –≤–Ω–∏–∑—É
    text = re.sub(r'\n\s*\d{1,3}\s*\n', '\n', text)
    # –ó–∞–≥–æ–ª–æ–≤–∫–∏ —Ç–∏–ø–∞ "–ì–ª–∞–≤–∞ 1. –ù–∞—á–∞–ª—å–Ω—ã–µ –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ —Å–≤–µ–¥–µ–Ω–∏—è"
    # (–æ—Å—Ç–∞–≤–ª—è–µ–º - —ç—Ç–æ –ø–æ–ª–µ–∑–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è)
    return text


# ===========================================
# –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
# ===========================================

def clean_ocr_text(text: str, aggressive: bool = True, use_dictionary: bool = True) -> str:
    """
    Apply all OCR cleaning steps.
    
    Args:
        text: Raw OCR text
        aggressive: If True, apply more aggressive fixes
        use_dictionary: If True, use dictionary-based word correction
        
    Returns:
        Cleaned text
    """
    if not text:
        return text
    
    # 1. –ü–µ—Ä–µ–Ω–æ—Å—ã (–¥–æ –¥—Ä—É–≥–∏—Ö –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π)
    text = fix_hyphenation(text)
    
    # 2. –õ–∞—Ç–∏–Ω–∏—Ü–∞ ‚Üí –ö–∏—Ä–∏–ª–ª–∏—Ü–∞
    text = fix_latin_to_cyrillic(text)
    
    # 3. –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã
    text = fix_math_symbols(text)
    
    # 4. –ö–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω—ã–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è (–ø–∞—Ç—Ç–µ—Ä–Ω—ã)
    text = apply_contextual_fixes(text)
    
    # 5. –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (–ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ, —Ñ–æ—Ä–º—É–ª—ã)
    text = fix_mathematical_context(text)
    
    # 6. –ì—Ä–∞–Ω–∏—Ü—ã –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
    text = fix_sentence_boundaries(text)
    
    # 7. –ù—É–º–µ—Ä–∞—Ü–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ - –º–æ–∂–µ—Ç –±—ã—Ç—å –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ)
    if aggressive:
        text = fix_numbering_in_context(text)
    
    # 8. –°–ª–æ–≤–∞—Ä–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ - –º–µ–¥–ª–µ–Ω–Ω–µ–µ)
    if use_dictionary and aggressive:
        text = fix_words_by_dictionary(text)
    
    # 9. –ü—Ä–æ–±–µ–ª—ã –∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã
    text = clean_whitespace(text)
    text = remove_page_artifacts(text)
    
    return text


# ===========================================
# –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ OCR
# ===========================================

def calculate_quality_score(text: str) -> dict:
    """
    Calculate OCR quality metrics.
    
    Returns:
        dict with quality metrics and issues found
    """
    issues = []
    
    # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ª–∞—Ç–∏–Ω–∏—Ü—É –≤ —Ä—É—Å—Å–∫–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
    latin_in_cyrillic = re.findall(r'[–∞-—è–ê-–Ø—ë–Å]+[a-zA-Z]+[–∞-—è–ê-–Ø—ë–Å]*|[a-zA-Z]+[–∞-—è–ê-–Ø—ë–Å]+', text)
    if latin_in_cyrillic:
        issues.append({
            'type': 'mixed_script',
            'count': len(latin_in_cyrillic),
            'examples': latin_in_cyrillic[:5]
        })
    
    # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–µ—Ç–∏–ø–∏—á–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
    unusual = re.findall(r'[@#$%&*{}|<>]', text)
    if unusual:
        issues.append({
            'type': 'unusual_chars',
            'count': len(unusual),
            'chars': list(set(unusual))
        })
    
    # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω—É–º–µ—Ä–∞—Ü–∏–∏
    numbers_in_lists = re.findall(r'\b(\d)\)', text)
    if numbers_in_lists:
        nums = [int(n) for n in numbers_in_lists]
        expected = list(range(nums[0], nums[0] + len(nums)))
        if nums != expected:
            issues.append({
                'type': 'numbering_error',
                'found': nums,
                'expected': expected
            })
    
    # 4. –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Ü–∏—Ñ—Ä –≤–Ω—É—Ç—Ä–∏ —Å–ª–æ–≤
    digits_in_words = re.findall(r'[–∞-—è–ê-–Ø]+\d+[–∞-—è–ê-–Ø]+', text)
    if digits_in_words:
        issues.append({
            'type': 'digits_in_words',
            'count': len(digits_in_words),
            'examples': digits_in_words[:5]
        })
    
    # –û–±—â–∏–π —Å–∫–æ—Ä (0-100)
    # –ù–∞—á–∏–Ω–∞–µ–º —Å 100, –≤—ã—á–∏—Ç–∞–µ–º –∑–∞ –∫–∞–∂–¥—É—é –ø—Ä–æ–±–ª–µ–º—É
    score = 100
    for issue in issues:
        if issue['type'] == 'mixed_script':
            score -= min(issue['count'] * 5, 30)
        elif issue['type'] == 'unusual_chars':
            score -= min(issue['count'] * 2, 10)
        elif issue['type'] == 'numbering_error':
            score -= 10
        elif issue['type'] == 'digits_in_words':
            score -= min(issue['count'] * 5, 20)
    
    return {
        'score': max(0, score),
        'issues': issues,
        'text_length': len(text),
        'word_count': len(text.split()),
    }


# ===========================================
# CLI
# ===========================================

if __name__ == "__main__":
    import sys
    
    # –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤
    test_cases = [
        # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–±–ª–µ–º–Ω—ã–π —Ç–µ–∫—Å—Ç
        """4. –ù–∞–π–¥–∏—Ç–µ —Å–º–µ–∂–Ω—ã–µ —É–≥–ª—ã, –µ—Å–ª–∏: 1) –æ–¥–∏–Ω –∏–∑ –Ω–∏—Ö –Ω–∞ 80¬∞ –±–æ–ª—å-
me –¥—Ä—É–≥–æ–≥–æ; 2) ux —Ä–∞–∑–Ω–æ—Å—Ç—å —Ä–∞–≤–Ω–∞ 40¬∞; 8) –æ–¥–∏–Ω –∏–∑ –Ω–∏—Ö –≤
3 pasa –º–µ–Ω—å—à–µ –¥—Ä—É–≥–æ–≥–æ; 4) OHH —Ä–∞–≤–Ω—ã.""",

        # –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        """–†–µ—à–∏—Ç–µ —É—Ä–∞–≤–Ω–µ–Ω–∏–µ: 2—Ö + 5 = 13. –ù–∞–π–¥–∏—Ç–µ –∑–Ω–∞—á–µ–Ω–∏–µ —É –ø—Ä–∏ —Ö = 4.""",
        
        # –¢–µ–æ—Ä–µ–º—ã –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
        """T–µ–æ—Ä–µ–º–∞ 1.2. C–º–µ–∂–Ω—ã–µ y–≥–ª—ã –≤ cy–º–º–µ —Ä–∞–≤–Ω—ã 180¬∞.
–î–æ–∫–∞3–∞—Ç–µ–ª—å—Å—Ç–≤–æ. –ü—É—Å—Ç—å —É–≥o–ª ABC –∏ —É–≥o–ª CBD - c–º–µ–∂–Ω—ã–µ.""",
        
        # –ß–∏—Å–ª–∞ –∏ –µ–¥–∏–Ω–∏—Ü—ã
        """–£–≥–æ–ª —Ä–∞–≤–µ–Ω 45 rpanyco–≤. –ù–∞–π–¥–∏—Ç–µ —Å–ºe.–Ω—ã–π —É–≥–æ–ª.""",
    ]
    
    for i, test_text in enumerate(test_cases, 1):
        print(f"\n{'='*60}")
        print(f"–¢–ï–°–¢ {i}")
        print('='*60)
        
        print("\nüìù –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç:")
        print(test_text)
        
        quality_before = calculate_quality_score(test_text)
        print(f"\nüìä –ö–∞—á–µ—Å—Ç–≤–æ –î–û: {quality_before['score']}/100")
        if quality_before['issues']:
            for issue in quality_before['issues']:
                print(f"   ‚ö†Ô∏è {issue['type']}: {issue.get('count', '')} {issue.get('examples', issue.get('chars', ''))[:3]}")
        
        print("\n‚ú® –ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏:")
        cleaned = clean_ocr_text(test_text)
        print(cleaned)
        
        quality_after = calculate_quality_score(cleaned)
        print(f"\nüìä –ö–∞—á–µ—Å—Ç–≤–æ –ü–û–°–õ–ï: {quality_after['score']}/100")
        print(f"üìà –£–ª—É—á—à–µ–Ω–∏–µ: +{quality_after['score'] - quality_before['score']}")
    
    print(f"\n{'='*60}")
    print("‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
