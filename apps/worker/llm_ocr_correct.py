"""
–ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ OCR —á–µ—Ä–µ–∑ OpenAI: –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
–∏ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Ñ–æ—Ä–º—É–ª –∫ –µ–¥–∏–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É, –ø—Ä–∏–≥–æ–¥–Ω–æ–º—É –¥–ª—è –ë–î, —á–∞—Ç–∞ –∏ —Å–∫—Ä–∏–ø—Ç–æ–≤.

–ë–µ–∑ —à–∞–±–ª–æ–Ω–Ω—ã—Ö –∑–∞–º–µ–Ω ‚Äî –º–æ–¥–µ–ª—å –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É (–ø—Ä–µ–¥–º–µ—Ç, —É—á–µ–±–Ω–∏–∫).
–ü–æ–¥–¥–µ—Ä–∂–∫–∞ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤: –ø—Ä–∏ —Å–±–æ–µ –º–æ–∂–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Å –º–µ—Å—Ç–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ (–±–µ–∑ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –≤—ã–∑–æ–≤–æ–≤ API).
"""

import json
import os
import re
from pathlib import Path
from typing import Callable, List, Optional


class LLMCancelRequested(Exception):
    """–ó–∞–ø—Ä–æ—à–µ–Ω–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ LLM-–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º."""
    pass

# –†–µ–≥—É–ª—è—Ä–∫–∞ –¥–ª—è —Ä–∞–∑–±–æ—Ä–∞ –æ—Ç–≤–µ—Ç–∞ –ø–æ –±–ª–æ–∫–∞–º ## –°—Ç—Ä–∞–Ω–∏—Ü–∞ N
PAGE_HEADER = re.compile(r"^##\s+–°—Ç—Ä–∞–Ω–∏—Ü–∞\s+(\d+)\s*$", re.IGNORECASE)

OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "")
OPENAI_MODEL = os.environ.get("OPENAI_MODEL_TEXT", "gpt-4o")

SYSTEM_PROMPT = """–¢—ã –∏—Å–ø—Ä–∞–≤–ª—è–µ—à—å —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ OCR —É—á–µ–±–Ω–∏–∫–∞. –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –æ—à–∏–±–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∏ –Ω–µ—É–¥–æ–±–Ω—ã–µ –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏—è —Ñ–æ—Ä–º—É–ª.

–ó–ê–î–ê–ß–ò:
1. –ò—Å–ø—Ä–∞–≤–∏—Ç—å –æ—à–∏–±–∫–∏ OCR: –ª–∞—Ç–∏–Ω–∏—Ü–∞ –≤–º–µ—Å—Ç–æ –∫–∏—Ä–∏–ª–ª–∏—Ü—ã (TEOPEMA ‚Üí –¢–ï–û–†–ï–ú–ê, CHHYCOB ‚Üí –°–ò–ù–£–°–û–í), –ø–µ—Ä–µ–ø—É—Ç–∞–Ω–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã (6‚Üîb, ?‚Üî¬≤), —Å–∫–ª–µ–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞.
2. –ü—Ä–∏–≤–µ—Å—Ç–∏ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–æ—Ä–º—É–ª—ã –∫ –µ–¥–∏–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É:
   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¢–û–õ–¨–ö–û —Å–∏–º–≤–æ–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ—Ç–æ–±—Ä–∞–∂–∞—é—Ç—Å—è –≤ –æ–±—ã—á–Ω–æ–º —Ç–µ–∫—Å—Ç–µ, –≤ –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä–∞—Ö –∏ –≤ –ë–î: Unicode (¬≤, ¬≥, ‚àö, ‚à†, ¬∞, √ó, √∑, œÄ, ‚â§, ‚â•, ‚â†, ‚àû, ¬±, ‚âà) –∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ ^ –¥–ª—è —Å—Ç–µ–ø–µ–Ω–∏ (x^2).
   - –ù–ï –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å LaTeX —Å –æ–±—Ä–∞—Ç–Ω—ã–º —Å–ª—ç—à–µ–º (\\frac, \\sqrt –∏ —Ç.–ø.).
   - –î—Ä–æ–±–∏: –∑–∞–ø–∏—Å—ã–≤–∞—Ç—å –∫–∞–∫ a/b –∏–ª–∏ –≤ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É —Å √∑.
   - –§–æ—Ä–º—É–ª—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø–æ–Ω—è—Ç–Ω—ã –∏ —á–µ–ª–æ–≤–µ–∫—É, –∏ —Å–∫—Ä–∏–ø—Ç–∞–º/LLM –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞.
3. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É: –∫–∞–∂–¥—ã–π –±–ª–æ–∫ –¥–æ–ª–∂–µ–Ω –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞ "## –°—Ç—Ä–∞–Ω–∏—Ü–∞ N" –∏ —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç —ç—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã. –ü–æ—Ä—è–¥–æ–∫ —Å—Ç—Ä–∞–Ω–∏—Ü –Ω–µ –º–µ–Ω—è—Ç—å.
4. –ö–æ–Ω—Ç–µ–∫—Å—Ç: —É—á–µ–±–Ω–∏–∫ –ø–æ —É–∫–∞–∑–∞–Ω–Ω–æ–º—É –ø—Ä–µ–¥–º–µ—Ç—É ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π –µ–≥–æ –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è —Ñ–æ—Ä–º—É–ª –∏ —Ç–µ—Ä–º–∏–Ω–æ–≤.
5. –£–¥–∞–ª—è—Ç—å –∫–æ–ª–æ–Ω—Ç–∏—Ç—É–ª—ã –∏ —Å–ª—É–∂–µ–±–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ –≤–µ—Ä—Å—Ç–∫–∏: –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–π—Å—è –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ö –∑–∞–≥–æ–ª–æ–≤–æ–∫ (–Ω–æ–º–µ—Ä –∫–ª–∞—Å—Å–∞, –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–µ–¥–º–µ—Ç–∞), –æ—Ç–¥–µ–ª—å–Ω–æ —Å—Ç–æ—è—â–∏–π –Ω–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã, –∫–æ—Ä–æ—Ç–∫–∏–µ —Å—Ç—Ä–æ–∫–∏ –∏–∑ –æ–¥–Ω–∏—Ö —Ü–∏—Ñ—Ä/–ø—Ä–æ–±–µ–ª–æ–≤. –û—Å—Ç–∞–≤–ª—è—Ç—å —Ç–æ–ª—å–∫–æ –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞, –∑–∞–¥–∞—á, –ø–æ–¥–ø–∏—Å–µ–π –∫ —Ä–∏—Å—É–Ω–∫–∞–º –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ. –ü–æ–¥–ø–∏—Å—å ¬´–†–∏—Å. N¬ª –≤–Ω—É—Ç—Ä–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω—è—Ç—å; —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ –∫ –ø–æ–¥–ø–∏—Å—è–º —Ä–∏—Å—É–Ω–∫–æ–≤ –ø—Ä–∏–º–µ—à–∞–Ω—ã –Ω–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏–ª–∏ –∫–ª–∞—Å—Å, ‚Äî –æ—á–∏—Å—Ç–∏—Ç—å –æ—Ç –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤.

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê: –≤–µ—Ä–Ω–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –≤ —Ç–æ–º –∂–µ –≤–∏–¥–µ ‚Äî –±–ª–æ–∫–∏ "## –°—Ç—Ä–∞–Ω–∏—Ü–∞ 1", "## –°—Ç—Ä–∞–Ω–∏—Ü–∞ 2", ... —Å –ø—É—Å—Ç–æ–π —Å—Ç—Ä–æ–∫–æ–π –ø–æ—Å–ª–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏ —Ç–µ–∫—Å—Ç–æ–º —Å—Ç—Ä–∞–Ω–∏—Ü—ã. –ù–∏–∫–∞–∫–∏—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –¥–æ –∏–ª–∏ –ø–æ—Å–ª–µ –±–ª–æ–∫–æ–≤."""


def _parse_pages_from_response(content: str) -> List[tuple[int, str]]:
    """–†–∞–∑–æ–±—Ä–∞—Ç—å –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ –ø–æ –±–ª–æ–∫–∞–º ## –°—Ç—Ä–∞–Ω–∏—Ü–∞ N. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç [(page_num, text), ...]."""
    result = []
    current_page = None
    current_lines = []
    for line in content.split("\n"):
        match = PAGE_HEADER.match(line.strip())
        if match:
            if current_page is not None:
                result.append((current_page, "\n".join(current_lines).strip()))
            current_page = int(match.group(1))
            current_lines = []
            continue
        if current_page is not None:
            current_lines.append(line)
    if current_page is not None:
        result.append((current_page, "\n".join(current_lines).strip()))
    return result


def _build_batch_chunk(page_texts: List[str], start_index: int) -> str:
    """–°–æ–±—Ä–∞—Ç—å –æ–¥–∏–Ω –±–∞—Ç—á –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏: ## –°—Ç—Ä–∞–Ω–∏—Ü–∞ (start+1) ... ## –°—Ç—Ä–∞–Ω–∏—Ü–∞ (start+len)."""
    lines = []
    for i, text in enumerate(page_texts):
        page_num = start_index + i + 1
        lines.append(f"## –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}")
        lines.append("")
        lines.append((text or "").strip())
        lines.append("")
    return "\n".join(lines).rstrip()


def _load_checkpoint(path: Path, total_pages: int, page_texts: List[str]) -> tuple[List[str], set[int]]:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏–∑ —á–µ–∫–ø–æ–∏–Ω—Ç–∞; –≤–µ—Ä–Ω—É—Ç—å (result, done_indices)."""
    result: List[str] = [""] * total_pages
    done_indices: set[int] = set()
    if not path.exists():
        return result, done_indices
    try:
        data = json.loads(path.read_text(encoding="utf-8"))
        done_list = data.get("done", [])
        done_indices = set(int(x) for x in done_list if 0 <= int(x) < total_pages)
        for i in range(total_pages):
            if str(i) in data and data[str(i)]:
                result[i] = data[str(i)]
            elif i not in done_indices:
                result[i] = page_texts[i] if i < len(page_texts) else ""
    except Exception:
        return [page_texts[i] if i < len(page_texts) else "" for i in range(total_pages)], set()
    for i in range(total_pages):
        if not result[i]:
            result[i] = page_texts[i] if i < len(page_texts) else ""
    return result, done_indices


def _save_checkpoint(path: Path, result: List[str], done_indices: set[int]) -> None:
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —á–µ–∫–ø–æ–∏–Ω—Ç (–ø–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω–æ) –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –ø–æ—Å–ª–µ —Å–±–æ—è."""
    path.parent.mkdir(parents=True, exist_ok=True)
    data = {"done": sorted(done_indices), **{str(i): result[i] for i in done_indices if i < len(result)}}
    path.write_text(json.dumps(data, ensure_ascii=False, indent=None), encoding="utf-8")


def correct_normalized_pages(
    page_texts: List[str],
    subject: str = "geometry",
    batch_size: int = 10,
    model: Optional[str] = None,
    checkpoint_path: Optional[Path] = None,
    progress_callback: Optional[Callable[[int, int], None]] = None,
    cancel_check: Optional[Callable[[], bool]] = None,
    quality_scores: Optional[List[float]] = None,
    llm_gate_threshold: float = 70.0,
) -> List[str]:
    """
    –ü—Ä–æ–≥–Ω–∞—Ç—å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –ø–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω—ã–π —Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ OpenAI –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è OCR –∏ —Ñ–æ—Ä–º—É–ª.

    –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–∞ —Å–∏–º–≤–æ–ª—ã –≤ —Ñ–æ—Ä–º—É–ª–∞—Ö –∑–∞–¥–∞–Ω—ã –≤ SYSTEM_PROMPT (Unicode + ^, –±–µ–∑ LaTeX).
    –ü—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ API –∫–ª—é—á–∞ –∏–ª–∏ –æ—à–∏–±–∫–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è –∏—Å—Ö–æ–¥–Ω—ã–π —Å–ø–∏—Å–æ–∫ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π.

    Cost control (PR8): –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω quality_scores (–¥–ª–∏–Ω–∞ == len(page_texts)), —Ç–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    —Å score >= llm_gate_threshold –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è—é—Ç—Å—è –≤ LLM ‚Äî –æ—Å—Ç–∞—ë—Ç—Å—è –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç.

    –ß–µ–∫–ø–æ–∏–Ω—Ç: –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω checkpoint_path, –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –±–∞—Ç—á–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è.
    –ü—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–º –∑–∞–ø—É—Å–∫–µ —Å —Ç–µ–º –∂–µ –ø—É—Ç—ë–º —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è—é—Ç—Å—è –≤ API —Å–Ω–æ–≤–∞.

    Args:
        page_texts: —Å–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤ —Å—Ç—Ä–∞–Ω–∏—Ü (–ø–æ—Å–ª–µ ocr_cleaner + formula_processor).
        subject: –ø—Ä–µ–¥–º–µ—Ç (geometry, math, physics, ...) –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
        batch_size: —Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–∞–Ω–∏—Ü –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –≤ –æ–¥–Ω–æ–º –∑–∞–ø—Ä–æ—Å–µ.
        model: –º–æ–¥–µ–ª—å OpenAI (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ env –∏–ª–∏ gpt-4o).
        checkpoint_path: –ø—É—Ç—å –∫ JSON-—á–µ–∫–ø–æ–∏–Ω—Ç—É –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –ø–æ—Å–ª–µ —Å–±–æ—è.
        progress_callback: –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –±–∞—Ç—á–∞ —Å (current, total).
        quality_scores: –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ —Å–ø–∏—Å–æ–∫ —Å–∫–æ—Ä–æ–≤ –∫–∞—á–µ—Å—Ç–≤–∞ (0‚Äì100) –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º; –ø—Ä–∏ score >= threshold LLM –Ω–µ –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è.
        llm_gate_threshold: –ø–æ—Ä–æ–≥ (0‚Äì100); —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å score >= –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è—é—Ç—Å—è –≤ LLM.

    Returns:
        –°–ø–∏—Å–æ–∫ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ —Ç–æ–π –∂–µ –¥–ª–∏–Ω—ã.
    """
    if not page_texts:
        return page_texts
    if not OPENAI_API_KEY:
        print("   ‚ö†Ô∏è  OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω, –ø—Ä–æ–ø—É—Å–∫ LLM-–∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ —Ñ–æ—Ä–º—É–ª")
        return page_texts

    try:
        from openai import OpenAI
    except ImportError:
        print("   ‚ö†Ô∏è  openai –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–ø—É—Å–∫ LLM-–∫–æ—Ä—Ä–µ–∫—Ü–∏–∏")
        return page_texts

    client = OpenAI(api_key=OPENAI_API_KEY)
    model_name = model or os.environ.get("OPENAI_MODEL_TEXT", OPENAI_MODEL)
    total_pages = len(page_texts)
    # –°—Ç—Ä–∞–Ω–∏—Ü—ã —Å score >= threshold –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ LLM (cost control)
    need_llm_set = set(range(total_pages))
    if quality_scores is not None and len(quality_scores) == total_pages:
        need_llm_set = {i for i in range(total_pages) if quality_scores[i] < llm_gate_threshold}
        skipped = total_pages - len(need_llm_set)
        if skipped:
            print(f"   üìä LLM gate: {skipped} —Å—Ç—Ä–∞–Ω–∏—Ü —Å –∫–∞—á–µ—Å—Ç–≤–æ–º >={llm_gate_threshold} –ø—Ä–æ–ø—É—â–µ–Ω—ã")

    done_indices: set[int] = set()
    if checkpoint_path:
        result, done_indices = _load_checkpoint(checkpoint_path, total_pages, page_texts)
        if done_indices:
            print(f"   üìÇ –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å —á–µ–∫–ø–æ–∏–Ω—Ç–∞: —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(done_indices)} —Å—Ç—Ä–∞–Ω–∏—Ü")
    else:
        result = [page_texts[i] if i < len(page_texts) else "" for i in range(total_pages)]

    total_batches = (total_pages + batch_size - 1) // batch_size

    for batch_idx in range(total_batches):
        if cancel_check and cancel_check():
            print("   ‚èπ –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
            for i in range(len(result)):
                if not result[i] and i < len(page_texts):
                    result[i] = page_texts[i]
            if checkpoint_path:
                try:
                    _save_checkpoint(checkpoint_path, result, done_indices)
                except Exception:
                    pass
            raise LLMCancelRequested()

        start = batch_idx * batch_size
        end = min(start + batch_size, total_pages)
        if checkpoint_path and all(i in done_indices for i in range(start, end)):
            if progress_callback:
                progress_callback(end, total_pages)
            continue

        # –¢–æ–ª—å–∫–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã, –∫–æ—Ç–æ—Ä—ã–º –Ω—É–∂–µ–Ω LLM, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ API; –æ—Å—Ç–∞–ª—å–Ω—ã–µ –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
        indices_to_send = [i for i in range(start, end) if i in need_llm_set and i not in done_indices]
        for i in range(start, end):
            if i not in need_llm_set:
                result[i] = page_texts[i] if i < len(page_texts) else ""
                done_indices.add(i)

        if not indices_to_send:
            if progress_callback:
                progress_callback(end, total_pages)
            continue

        # –°–æ–±–∏—Ä–∞–µ–º –æ–¥–∏–Ω –±–ª–æ–∫ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏: —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏–∑ indices_to_send
        chunk_lines = []
        for i in indices_to_send:
            chunk_lines.append(f"## –°—Ç—Ä–∞–Ω–∏—Ü–∞ {i + 1}")
            chunk_lines.append("")
            chunk_lines.append((page_texts[i] if i < len(page_texts) else "").strip())
            chunk_lines.append("")
        chunk = "\n".join(chunk_lines).rstrip()

        if not chunk.strip():
            for i in indices_to_send:
                result[i] = page_texts[i] if i < len(page_texts) else ""
                done_indices.add(i)
            if checkpoint_path:
                _save_checkpoint(checkpoint_path, result, done_indices)
            if progress_callback:
                progress_callback(end, total_pages)
            continue

        user_content = f"–ü—Ä–µ–¥–º–µ—Ç: {subject}.\n\n–ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç (–±–ª–æ–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü):\n\n{chunk}"

        try:
            resp = client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": user_content},
                ],
                temperature=0.2,
            )
            answer = (resp.choices[0].message.content or "").strip()
            parsed = _parse_pages_from_response(answer)
            for page_num, text in parsed:
                idx = page_num - 1
                if 0 <= idx < len(result):
                    result[idx] = text
            for i in indices_to_send:
                if not result[i] and i < len(page_texts):
                    result[i] = page_texts[i]
                done_indices.add(i)
            if checkpoint_path:
                _save_checkpoint(checkpoint_path, result, done_indices)
        except Exception as e:
            print(f"   ‚ö†Ô∏è  LLM-–∫–æ—Ä—Ä–µ–∫—Ü–∏—è –±–∞—Ç—á–∞ {batch_idx + 1}/{total_batches}: {e}")
            for i in indices_to_send:
                result[i] = page_texts[i] if i < len(page_texts) else ""
            if checkpoint_path:
                _save_checkpoint(checkpoint_path, result, done_indices)

        if progress_callback:
            progress_callback(min(end, total_pages), total_pages)
        if (batch_idx + 1) % 5 == 0 or batch_idx == total_batches - 1:
            print(f"   ü§ñ LLM-–∫–æ—Ä—Ä–µ–∫—Ü–∏—è: {min(end, total_pages)}/{total_pages} —Å—Ç—Ä–∞–Ω–∏—Ü")

    for i in range(len(result)):
        if not result[i] and i < len(page_texts):
            result[i] = page_texts[i]

    if checkpoint_path and checkpoint_path.exists():
        try:
            checkpoint_path.unlink()
        except Exception:
            pass
    return result
