"""
–ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ OCR —á–µ—Ä–µ–∑ OpenAI: –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
–∏ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Ñ–æ—Ä–º—É–ª –∫ –µ–¥–∏–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É, –ø—Ä–∏–≥–æ–¥–Ω–æ–º—É –¥–ª—è –ë–î, —á–∞—Ç–∞ –∏ —Å–∫—Ä–∏–ø—Ç–æ–≤.

–ë–µ–∑ —à–∞–±–ª–æ–Ω–Ω—ã—Ö –∑–∞–º–µ–Ω ‚Äî –º–æ–¥–µ–ª—å –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É (–ø—Ä–µ–¥–º–µ—Ç, —É—á–µ–±–Ω–∏–∫).
"""

import os
import re
from typing import List, Optional

# –†–µ–≥—É–ª—è—Ä–∫–∞ –¥–ª—è —Ä–∞–∑–±–æ—Ä–∞ –æ—Ç–≤–µ—Ç–∞ –ø–æ –±–ª–æ–∫–∞–º ## –°—Ç—Ä–∞–Ω–∏—Ü–∞ N
PAGE_HEADER = re.compile(r"^##\s+–°—Ç—Ä–∞–Ω–∏—Ü–∞\s+(\d+)\s*$", re.IGNORECASE)

OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "")
OPENAI_MODEL = os.environ.get("OPENAI_MODEL_TEXT", "gpt-4o")

SYSTEM_PROMPT = """–¢—ã –∏—Å–ø—Ä–∞–≤–ª—è–µ—à—å —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ OCR —É—á–µ–±–Ω–∏–∫–∞. –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –æ—à–∏–±–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∏ –Ω–µ—É–¥–æ–±–Ω—ã–µ –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏—è —Ñ–æ—Ä–º—É–ª.

–ó–ê–î–ê–ß–ò:
1. –ò—Å–ø—Ä–∞–≤–∏—Ç—å –æ—à–∏–±–∫–∏ OCR: –ª–∞—Ç–∏–Ω–∏—Ü–∞ –≤–º–µ—Å—Ç–æ –∫–∏—Ä–∏–ª–ª–∏—Ü—ã (TEOPEMA ‚Üí –¢–ï–û–†–ï–ú–ê, CHHYCOB ‚Üí –°–ò–ù–£–°–û–í), –ø–µ—Ä–µ–ø—É—Ç–∞–Ω–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã (6‚Üîb, ?‚Üî¬≤), —Å–∫–ª–µ–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞.
2. –ü—Ä–∏–≤–µ—Å—Ç–∏ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–æ—Ä–º—É–ª—ã –∫ –µ–¥–∏–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É:
   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¢–û–õ–¨–ö–û —Å–∏–º–≤–æ–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ—Ç–æ–±—Ä–∞–∂–∞—é—Ç—Å—è –≤ –æ–±—ã—á–Ω–æ–º —Ç–µ–∫—Å—Ç–µ, –≤ –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä–∞—Ö –∏ –≤ –ë–î: Unicode (¬≤, ¬≥, ‚àö, ‚à†, ¬∞, √ó, √∑, œÄ, ‚â§, ‚â•, ‚â†, ‚àû, ¬±, ‚âà) –∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ ^ –¥–ª—è —Å—Ç–µ–ø–µ–Ω–∏ (x^2).
   - –ù–ï –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å LaTeX —Å –æ–±—Ä–∞—Ç–Ω—ã–º —Å–ª—ç—à–µ–º (\\frac, \\sqrt –∏ —Ç.–ø.).
   - –î—Ä–æ–±–∏: –∑–∞–ø–∏—Å—ã–≤–∞—Ç—å –∫–∞–∫ a/b –∏–ª–∏ –≤ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É —Å √∑.
   - –§–æ—Ä–º—É–ª—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø–æ–Ω—è—Ç–Ω—ã –∏ —á–µ–ª–æ–≤–µ–∫—É, –∏ —Å–∫—Ä–∏–ø—Ç–∞–º/LLM –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞.
3. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É: –∫–∞–∂–¥—ã–π –±–ª–æ–∫ –¥–æ–ª–∂–µ–Ω –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞ "## –°—Ç—Ä–∞–Ω–∏—Ü–∞ N" –∏ —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç —ç—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã. –ü–æ—Ä—è–¥–æ–∫ —Å—Ç—Ä–∞–Ω–∏—Ü –Ω–µ –º–µ–Ω—è—Ç—å.
4. –ö–æ–Ω—Ç–µ–∫—Å—Ç: —É—á–µ–±–Ω–∏–∫ –ø–æ —É–∫–∞–∑–∞–Ω–Ω–æ–º—É –ø—Ä–µ–¥–º–µ—Ç—É ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π –µ–≥–æ –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è —Ñ–æ—Ä–º—É–ª –∏ —Ç–µ—Ä–º–∏–Ω–æ–≤.

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê: –≤–µ—Ä–Ω–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –≤ —Ç–æ–º –∂–µ –≤–∏–¥–µ ‚Äî –±–ª–æ–∫–∏ "## –°—Ç—Ä–∞–Ω–∏—Ü–∞ 1", "## –°—Ç—Ä–∞–Ω–∏—Ü–∞ 2", ... —Å –ø—É—Å—Ç–æ–π —Å—Ç—Ä–æ–∫–æ–π –ø–æ—Å–ª–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏ —Ç–µ–∫—Å—Ç–æ–º —Å—Ç—Ä–∞–Ω–∏—Ü—ã. –ù–∏–∫–∞–∫–∏—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –¥–æ –∏–ª–∏ –ø–æ—Å–ª–µ –±–ª–æ–∫–æ–≤."""


def _parse_pages_from_response(content: str) -> List[tuple[int, str]]:
    """–†–∞–∑–æ–±—Ä–∞—Ç—å –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ –ø–æ –±–ª–æ–∫–∞–º ## –°—Ç—Ä–∞–Ω–∏—Ü–∞ N. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç [(page_num, text), ...]."""
    result = []
    current_page = None
    current_lines = []
    for line in content.split("\n"):
        match = PAGE_HEADER.match(line.strip())
        if match:
            if current_page is not None:
                result.append((current_page, "\n".join(current_lines).strip()))
            current_page = int(match.group(1))
            current_lines = []
            continue
        if current_page is not None:
            current_lines.append(line)
    if current_page is not None:
        result.append((current_page, "\n".join(current_lines).strip()))
    return result


def _build_batch_chunk(page_texts: List[str], start_index: int) -> str:
    """–°–æ–±—Ä–∞—Ç—å –æ–¥–∏–Ω –±–∞—Ç—á –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏: ## –°—Ç—Ä–∞–Ω–∏—Ü–∞ (start+1) ... ## –°—Ç—Ä–∞–Ω–∏—Ü–∞ (start+len)."""
    lines = []
    for i, text in enumerate(page_texts):
        page_num = start_index + i + 1
        lines.append(f"## –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}")
        lines.append("")
        lines.append((text or "").strip())
        lines.append("")
    return "\n".join(lines).rstrip()


def correct_normalized_pages(
    page_texts: List[str],
    subject: str = "geometry",
    batch_size: int = 10,
    model: Optional[str] = None,
) -> List[str]:
    """
    –ü—Ä–æ–≥–Ω–∞—Ç—å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –ø–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω—ã–π —Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ OpenAI –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è OCR –∏ —Ñ–æ—Ä–º—É–ª.

    –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–∞ —Å–∏–º–≤–æ–ª—ã –≤ —Ñ–æ—Ä–º—É–ª–∞—Ö –∑–∞–¥–∞–Ω—ã –≤ SYSTEM_PROMPT (Unicode + ^, –±–µ–∑ LaTeX).
    –ü—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ API –∫–ª—é—á–∞ –∏–ª–∏ –æ—à–∏–±–∫–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è –∏—Å—Ö–æ–¥–Ω—ã–π —Å–ø–∏—Å–æ–∫ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π.

    Args:
        page_texts: —Å–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤ —Å—Ç—Ä–∞–Ω–∏—Ü (–ø–æ—Å–ª–µ ocr_cleaner).
        subject: –ø—Ä–µ–¥–º–µ—Ç (geometry, math, physics, ...) –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
        batch_size: —Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–∞–Ω–∏—Ü –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –≤ –æ–¥–Ω–æ–º –∑–∞–ø—Ä–æ—Å–µ.
        model: –º–æ–¥–µ–ª—å OpenAI (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ env –∏–ª–∏ gpt-4o).

    Returns:
        –°–ø–∏—Å–æ–∫ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ —Ç–æ–π –∂–µ –¥–ª–∏–Ω—ã.
    """
    if not page_texts:
        return page_texts
    if not OPENAI_API_KEY:
        print("   ‚ö†Ô∏è  OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω, –ø—Ä–æ–ø—É—Å–∫ LLM-–∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ —Ñ–æ—Ä–º—É–ª")
        return page_texts

    try:
        from openai import OpenAI
    except ImportError:
        print("   ‚ö†Ô∏è  openai –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–ø—É—Å–∫ LLM-–∫–æ—Ä—Ä–µ–∫—Ü–∏–∏")
        return page_texts

    client = OpenAI(api_key=OPENAI_API_KEY)
    model_name = model or os.environ.get("OPENAI_MODEL_TEXT", OPENAI_MODEL)
    result: List[str] = [""] * len(page_texts)  # –∑–∞–ø–æ–ª–Ω–∏–º –ø–æ –∏–Ω–¥–µ–∫—Å–∞–º
    total_batches = (len(page_texts) + batch_size - 1) // batch_size

    for batch_idx in range(total_batches):
        start = batch_idx * batch_size
        end = min(start + batch_size, len(page_texts))
        batch = page_texts[start:end]
        chunk = _build_batch_chunk(batch, start)
        if not chunk.strip():
            for i in range(start, end):
                result[i] = page_texts[i]
            continue

        user_content = f"–ü—Ä–µ–¥–º–µ—Ç: {subject}.\n\n–ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç (–±–ª–æ–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü):\n\n{chunk}"

        try:
            resp = client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": user_content},
                ],
                temperature=0.2,
            )
            answer = (resp.choices[0].message.content or "").strip()
            parsed = _parse_pages_from_response(answer)
            for page_num, text in parsed:
                idx = page_num - 1
                if 0 <= idx < len(result):
                    result[idx] = text
            # –°—Ç—Ä–∞–Ω–∏—Ü—ã, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ –æ–∫–∞–∑–∞–ª–æ—Å—å –≤ –æ—Ç–≤–µ—Ç–µ, –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –±—ã–ª–∏
            for i in range(start, end):
                if not result[i] and i < len(page_texts):
                    result[i] = page_texts[i]
        except Exception as e:
            print(f"   ‚ö†Ô∏è  LLM-–∫–æ—Ä—Ä–µ–∫—Ü–∏—è –±–∞—Ç—á–∞ {batch_idx + 1}/{total_batches}: {e}")
            for i in range(start, end):
                result[i] = page_texts[i]

        if (batch_idx + 1) % 5 == 0 or batch_idx == total_batches - 1:
            print(f"   ü§ñ LLM-–∫–æ—Ä—Ä–µ–∫—Ü–∏—è: {min(end, len(page_texts))}/{len(page_texts)} —Å—Ç—Ä–∞–Ω–∏—Ü")

    # –ó–∞–ø–æ–ª–Ω–∏—Ç—å –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–æ–ø—É—Å–∫–∏
    for i in range(len(result)):
        if not result[i] and i < len(page_texts):
            result[i] = page_texts[i]
    return result
